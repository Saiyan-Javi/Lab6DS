{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c896f7bb",
   "metadata": {},
   "source": [
    "# Laboratorio 6\n",
    "## Data Science\n",
    "Javier Alejandro Ovalle Chiquín, 22103  \n",
    "José Ángel Morales Farfán, 22689  \n",
    "Ricardo Josué Morales Contreras, 22289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dccd1ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json, re\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c6df7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traficogt: (5604, 19)\n",
      "              tweet_id                      date         username  \\\n",
      "0  1834236045598056867 2024-09-12 14:22:06+00:00        traficogt   \n",
      "1  1834029142565658846 2024-09-12 00:39:56+00:00     monymmorales   \n",
      "2  1834039491826180424 2024-09-12 01:21:04+00:00  animaldgalaccia   \n",
      "3  1833963729136091179 2024-09-11 20:20:01+00:00   EstacionDobleA   \n",
      "4  1833665391698092330 2024-09-11 00:34:31+00:00       CubReserva   \n",
      "\n",
      "                 displayname  \\\n",
      "0                  traficoGT   \n",
      "1                       Mony   \n",
      "2           Jairo De La Nada   \n",
      "3           Estación Doble A   \n",
      "4  CUB Reserva Kanajuyu Z 16   \n",
      "\n",
      "                                                text  reply_count  \\\n",
      "0  Es comprensible la resolución... El ruso sabe ...          NaN   \n",
      "1  La corrupción de la @CC_Guatemala\\nes descarad...          NaN   \n",
      "2  @PNCdeGuatemala @mingobguate @FJimenezmingob @...          NaN   \n",
      "3  @amilcarmontejo @AztecaNoticiaGT @BancadaSemil...          NaN   \n",
      "4  @soy_502 @AztecaNoticiaGT @CONAPgt @DenunciaEM...          NaN   \n",
      "\n",
      "   retweet_count  like_count  quote_count  is_retweet  is_quote  \\\n",
      "0            NaN         1.0          NaN       False      True   \n",
      "1           56.0        84.0          4.0       False     False   \n",
      "2            NaN         1.0          NaN       False     False   \n",
      "3            NaN         NaN          NaN       False     False   \n",
      "4            NaN         1.0          NaN       False     False   \n",
      "\n",
      "  in_reply_to_user                                    mentioned_users  \\\n",
      "0             None                                                 []   \n",
      "1             None                                     [CC_Guatemala]   \n",
      "2   PNCdeGuatemala  [PNCdeGuatemala, mingobguate, FJimenezmingob, ...   \n",
      "3   EstacionDobleA  [amilcarmontejo, AztecaNoticiaGT, BancadaSemil...   \n",
      "4       CubReserva  [soy_502, AztecaNoticiaGT, CONAPgt, DenunciaEM...   \n",
      "\n",
      "  hashtags                                              links  \\\n",
      "0       []                                                 []   \n",
      "1       []  [https://www.prensalibre.com/guatemala/justici...   \n",
      "2       []                                                 []   \n",
      "3       []                                                 []   \n",
      "4       []                                                 []   \n",
      "\n",
      "                                                 url lang  \\\n",
      "0  https://x.com/traficogt/status/183423604559805...   es   \n",
      "1  https://x.com/monymmorales/status/183402914256...   es   \n",
      "2  https://x.com/animaldgalaccia/status/183403949...  qme   \n",
      "3  https://x.com/EstacionDobleA/status/1833963729...  qam   \n",
      "4  https://x.com/CubReserva/status/18336653916980...   es   \n",
      "\n",
      "           sourceLabel                date_local  \n",
      "0  Twitter for Android 2024-09-12 08:22:06-06:00  \n",
      "1  Twitter for Android 2024-09-11 18:39:56-06:00  \n",
      "2   Twitter for iPhone 2024-09-11 19:21:04-06:00  \n",
      "3  Twitter for Android 2024-09-11 14:20:01-06:00  \n",
      "4  Twitter for Android 2024-09-10 18:34:31-06:00  \n"
     ]
    }
   ],
   "source": [
    "# ---------- Lectura robusta ----------\n",
    "def read_text_robust(path):\n",
    "    for enc in (\"utf-8-sig\", \"utf-16\", \"latin-1\", \"utf-8\"):\n",
    "        try:\n",
    "            with open(path, \"r\", encoding=enc) as f:\n",
    "                return f.read()\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read().decode(\"utf-8\", \"ignore\")\n",
    "\n",
    "# ---------- Parser JSONL tolerante ----------\n",
    "def parse_jsonl(content: str):\n",
    "    recs = []\n",
    "    for line in content.strip().splitlines():\n",
    "        s = line.strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        # quitar coma final y quedarnos con {...}\n",
    "        if s.endswith(\",\"):\n",
    "            s = s[:-1].rstrip()\n",
    "        if \"{\" in s and \"}\" in s:\n",
    "            s = s[s.find(\"{\"): s.rfind(\"}\") + 1]\n",
    "        try:\n",
    "            obj = json.loads(s)\n",
    "            if isinstance(obj, dict):\n",
    "                recs.append(obj)\n",
    "        except Exception:\n",
    "            # si una línea falla, la saltamos\n",
    "            continue\n",
    "    return recs\n",
    "\n",
    "# ---------- Normalización a columnas ----------\n",
    "def flatten_tweet(obj: dict) -> dict:\n",
    "    user = obj.get(\"user\") or {}\n",
    "    if isinstance(user, dict):\n",
    "        username    = user.get(\"username\") or user.get(\"screen_name\")\n",
    "        displayname = user.get(\"displayname\") or user.get(\"name\")\n",
    "    else:\n",
    "        username, displayname = (None, None)\n",
    "\n",
    "    # mentionedUsers puede venir como lista de dicts\n",
    "    musers = []\n",
    "    if isinstance(obj.get(\"mentionedUsers\"), list):\n",
    "        for m in obj[\"mentionedUsers\"]:\n",
    "            if isinstance(m, dict):\n",
    "                u = m.get(\"username\") or m.get(\"screen_name\")\n",
    "                if u: musers.append(u)\n",
    "\n",
    "    # hashtags pueden venir como lista de strings\n",
    "    hashtags = obj.get(\"hashtags\") if isinstance(obj.get(\"hashtags\"), list) else []\n",
    "\n",
    "    # links pueden venir como lista de dicts con 'url'\n",
    "    links = []\n",
    "    if isinstance(obj.get(\"links\"), list):\n",
    "        for l in obj[\"links\"]:\n",
    "            if isinstance(l, dict):\n",
    "                u = l.get(\"url\") or l.get(\"expanded_url\")\n",
    "                if u: links.append(u)\n",
    "\n",
    "    in_reply_to_user = None\n",
    "    if isinstance(obj.get(\"inReplyToUser\"), dict):\n",
    "        in_reply_to_user = obj[\"inReplyToUser\"].get(\"username\") or obj[\"inReplyToUser\"].get(\"screen_name\")\n",
    "\n",
    "    return {\n",
    "        \"tweet_id\": str(obj.get(\"id\") or obj.get(\"id_str\") or \"\"),\n",
    "        \"url\": obj.get(\"url\"),\n",
    "        \"date\": pd.to_datetime(obj.get(\"date\"), utc=True, errors=\"coerce\"),\n",
    "        \"username\": username,\n",
    "        \"displayname\": displayname,\n",
    "        \"text\": obj.get(\"rawContent\") or obj.get(\"full_text\") or obj.get(\"text\"),\n",
    "        \"reply_count\": obj.get(\"replyCount\") or obj.get(\"reply_count\"),\n",
    "        \"retweet_count\": obj.get(\"retweetCount\") or obj.get(\"retweet_count\"),\n",
    "        \"like_count\": obj.get(\"likeCount\") or obj.get(\"favorite_count\"),\n",
    "        \"quote_count\": obj.get(\"quoteCount\") or obj.get(\"quote_count\"),\n",
    "        \"mentioned_users\": musers,\n",
    "        \"hashtags\": hashtags,\n",
    "        \"links\": links,\n",
    "        \"is_retweet\": obj.get(\"retweetedTweet\") is not None,\n",
    "        \"is_quote\": obj.get(\"quotedTweet\") is not None,\n",
    "        \"in_reply_to_user\": in_reply_to_user,\n",
    "        \"lang\": obj.get(\"lang\"),\n",
    "        \"sourceLabel\": obj.get(\"sourceLabel\") or obj.get(\"source\"),\n",
    "    }\n",
    "\n",
    "def load_tweets(path: str) -> pd.DataFrame:\n",
    "    content = read_text_robust(path)\n",
    "    recs = parse_jsonl(content)\n",
    "    rows = [flatten_tweet(r) for r in recs]\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # columnas ordenadas\n",
    "    order = [\"tweet_id\",\"date\",\"username\",\"displayname\",\"text\",\n",
    "             \"reply_count\",\"retweet_count\",\"like_count\",\"quote_count\",\n",
    "             \"is_retweet\",\"is_quote\",\"in_reply_to_user\",\n",
    "             \"mentioned_users\",\"hashtags\",\"links\",\"url\",\"lang\",\"sourceLabel\"]\n",
    "    df = df[[c for c in order if c in df.columns]].copy()\n",
    "\n",
    "    # opcional: fecha local\n",
    "    if \"date\" in df and pd.api.types.is_datetime64_any_dtype(df[\"date\"]):\n",
    "        try:\n",
    "            df[\"date_local\"] = df[\"date\"].dt.tz_convert(\"America/Guatemala\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    return df\n",
    "\n",
    "# --------- Usa el loader con tus archivos ----------\n",
    "df_trafico  = load_tweets(\"traficogt.txt\")\n",
    "# Si también tienes 'tioberny.txt', descomenta:\n",
    "# df_tioberny = load_tweets(\"tioberny.txt\")\n",
    "\n",
    "print(\"traficogt:\", df_trafico.shape)\n",
    "print(df_trafico.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b004b6f8",
   "metadata": {},
   "source": [
    "#### 3) Limpieza de los datos   \n",
    "\n",
    "#### 3.1) Quitar caracteres especiales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8937e095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Es comprensible la resolución... El ruso sabe ...   \n",
      "1  La corrupción de la @CC_Guatemala\\nes descarad...   \n",
      "2  @PNCdeGuatemala @mingobguate @FJimenezmingob @...   \n",
      "3  @amilcarmontejo @AztecaNoticiaGT @BancadaSemil...   \n",
      "4  @soy_502 @AztecaNoticiaGT @CONAPgt @DenunciaEM...   \n",
      "5  @amilcarmontejo @PMTMuniGuate @Noti7Guatemala ...   \n",
      "6  Favor compartir  \\nEl vive el zona 7 Bethania ...   \n",
      "7  @traficogt @_ojoconmipisto @soy_502 @AztecaNot...   \n",
      "8  @piero_coen @FJimenezmingob @traficogt @mingob...   \n",
      "9  @erwin_fern84019 @piero_coen @FJimenezmingob @...   \n",
      "\n",
      "                                          text_clean  \n",
      "0  comprensible resolución ruso sabe engrasar maq...  \n",
      "1  corrupción descarada falsificación documentos ...  \n",
      "2                                                     \n",
      "3                                                     \n",
      "4  urgente zona deterioro tala inmoderada tráfico...  \n",
      "5  avenidas y calles avenida calle luz semáforo y...  \n",
      "6                 favor compartir vive zona bethania  \n",
      "7              importante ponerle atención vecinos z  \n",
      "8                          son pajas mota ahora vale  \n",
      "9   ayyyy arde fumen mota mejor segui chimando bebes  \n"
     ]
    }
   ],
   "source": [
    "# --- Expresiones regulares ---\n",
    "URL_RE      = re.compile(r\"https?://\\S+\")\n",
    "MENTION_RE  = re.compile(r\"@\\w{1,20}\")\n",
    "HASHTAG_RE  = re.compile(r\"#\\w+\")\n",
    "EMOJI_RE    = re.compile(\n",
    "    \"[\" \n",
    "    \"\\U0001F300-\\U0001F5FF\"  # símbolos y pictogramas\n",
    "    \"\\U0001F600-\\U0001F64F\"  # emoticones\n",
    "    \"\\U0001F680-\\U0001F6FF\"  # transporte\n",
    "    \"\\U0001F700-\\U0001F77F\"\n",
    "    \"\\U0001F900-\\U0001F9FF\"\n",
    "    \"\\U00002600-\\U000026FF\"  # misceláneos\n",
    "    \"\\U00002700-\\U000027BF\"\n",
    "    \"]+\", flags=re.UNICODE\n",
    ")\n",
    "NONWORD_RE  = re.compile(r\"[^a-záéíóúñü\\s]\")  # quita números y símbolos\n",
    "MULTISPACE  = re.compile(r\"\\s+\")\n",
    "\n",
    "# Stopwords en español (artículos, preposiciones, conjunciones)\n",
    "STOPWORDS_ES = set(\"\"\"\n",
    "a al algo algunas alguno algunos ante antes como con contra cual cuales cuando de del desde donde\n",
    "el la los las un una unos unas\n",
    "e en entre era erais éramos eran es esa esas ese eso esos esta estas este estos\n",
    "haber había habían habrá hay hasta incluso mas más me mi mis muy nada ni no nos nosotros\n",
    "o os otra otras otro otros para pero poco por porque que se sea sean ser será si sido sin sobre soy\n",
    "su sus tal también tampoco tan tanto te tener tenía tenían tengo ti tuvo usted ustedes ya yo\n",
    "\"\"\".split())\n",
    "\n",
    "# --- Función de limpieza ---\n",
    "def clean_text_31(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    s = s.lower()                         # minúsculas\n",
    "    s = URL_RE.sub(\" \", s)                # quitar urls\n",
    "    s = EMOJI_RE.sub(\" \", s)              # quitar emoticones\n",
    "    s = MENTION_RE.sub(\" \", s)            # quitar menciones @\n",
    "    s = HASHTAG_RE.sub(\" \", s)            # quitar hashtags #\n",
    "    s = NONWORD_RE.sub(\" \", s)            # quitar signos y números\n",
    "    s = MULTISPACE.sub(\" \", s).strip()    # espacios múltiples -> uno solo\n",
    "    # eliminar stopwords\n",
    "    tokens = [t for t in s.split() if t not in STOPWORDS_ES]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# --- Aplicar sobre tu DataFrame ---\n",
    "df_trafico[\"text_clean\"] = df_trafico[\"text\"].apply(clean_text_31)\n",
    "\n",
    "# Vista previa\n",
    "print(df_trafico[[\"text\",\"text_clean\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37f58ba",
   "metadata": {},
   "source": [
    "#### 3.2) Extraer menciones, respuestas y rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2255043e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets con relaciones: (5604, 26)\n",
      "Aristas construidas: (15009, 5)\n",
      "               src              dst     type             tweet_id  \\\n",
      "0     monymmorales     cc_guatemala  mention  1834029142565658846   \n",
      "1  animaldgalaccia   pncdeguatemala  mention  1834039491826180424   \n",
      "2  animaldgalaccia      mingobguate  mention  1834039491826180424   \n",
      "3  animaldgalaccia   fjimenezmingob  mention  1834039491826180424   \n",
      "4  animaldgalaccia     diegoedeleon  mention  1834039491826180424   \n",
      "5  animaldgalaccia   amilcarmontejo  mention  1834039491826180424   \n",
      "6  animaldgalaccia        traficogt  mention  1834039491826180424   \n",
      "7  animaldgalaccia   pncdeguatemala    reply  1834039491826180424   \n",
      "8   estaciondoblea   amilcarmontejo  mention  1833963729136091179   \n",
      "9   estaciondoblea  aztecanoticiagt  mention  1833963729136091179   \n",
      "\n",
      "                       date  \n",
      "0 2024-09-12 00:39:56+00:00  \n",
      "1 2024-09-12 01:21:04+00:00  \n",
      "2 2024-09-12 01:21:04+00:00  \n",
      "3 2024-09-12 01:21:04+00:00  \n",
      "4 2024-09-12 01:21:04+00:00  \n",
      "5 2024-09-12 01:21:04+00:00  \n",
      "6 2024-09-12 01:21:04+00:00  \n",
      "7 2024-09-12 01:21:04+00:00  \n",
      "8 2024-09-11 20:20:01+00:00  \n",
      "9 2024-09-11 20:20:01+00:00  \n"
     ]
    }
   ],
   "source": [
    "# --- Patrones útiles ---\n",
    "MENTION_RE = re.compile(r'@([A-Za-z0-9_]{1,20})')\n",
    "RETWEET_RE = re.compile(r'^\\s*rt\\s+@([A-Za-z0-9_]{1,20})', re.IGNORECASE)\n",
    "REPLY_HEAD_RE = re.compile(r'^\\s*@([A-Za-z0-9_]{1,20})')  # a veces las respuestas empiezan con @user\n",
    "\n",
    "def safe_list(x):\n",
    "    return x if isinstance(x, list) else ([] if pd.isna(x) or x is None else list(x))\n",
    "\n",
    "def extract_relations(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) MENCIONES: usar campo estructurado si existe; si no, extraer del texto\n",
    "    if \"mentioned_users\" in df.columns:\n",
    "        mentions_col = df[\"mentioned_users\"].apply(safe_list)\n",
    "    else:\n",
    "        mentions_col = df[\"text\"].fillna(\"\").apply(lambda s: list(set(MENTION_RE.findall(s))))\n",
    "\n",
    "    df[\"mentions_extracted\"] = mentions_col\n",
    "    df[\"n_mentions\"] = df[\"mentions_extracted\"].apply(len)\n",
    "\n",
    "    # 2) RESPUESTAS: usar campo estructurado si existe; si no, inferir del inicio del texto\n",
    "    if \"in_reply_to_user\" in df.columns:\n",
    "        reply_to = df[\"in_reply_to_user\"]\n",
    "    else:\n",
    "        reply_to = df[\"text\"].fillna(\"\").apply(lambda s: (REPLY_HEAD_RE.match(s) or [None, None])[1])\n",
    "\n",
    "    df[\"reply_to_user\"] = reply_to\n",
    "    df[\"is_reply\"] = df[\"reply_to_user\"].notna()\n",
    "\n",
    "    # 3) RETWEETS: usar bandera/campo estructurado si existe; si no, inferir con \"RT @user\"\n",
    "    if \"is_retweet\" in df.columns:\n",
    "        is_rt = df[\"is_retweet\"].fillna(False).astype(bool)\n",
    "    else:\n",
    "        is_rt = df[\"text\"].fillna(\"\").str.contains(r'^\\s*rt\\s+@', case=False, na=False)\n",
    "\n",
    "    df[\"is_retweet_flag\"] = is_rt\n",
    "\n",
    "    # Usuario retuiteado: preferir estructura si existiera; si no, regex\n",
    "    if \"retweeted_user\" in df.columns:\n",
    "        rt_user = df[\"retweeted_user\"]\n",
    "    else:\n",
    "        rt_user = df[\"text\"].fillna(\"\").apply(lambda s: (RETWEET_RE.match(s) or [None, None])[1])\n",
    "\n",
    "    df[\"retweet_user\"] = rt_user\n",
    "\n",
    "    # 4) Construir aristas dirigidas (src -> dst) por tipo de interacción\n",
    "    edges = []\n",
    "\n",
    "    for _, r in df.iterrows():\n",
    "        src = r.get(\"username\")\n",
    "        tid = r.get(\"tweet_id\")\n",
    "        dt  = r.get(\"date\")\n",
    "\n",
    "        # mention edges\n",
    "        for dst in r.get(\"mentions_extracted\", []):\n",
    "            if src and dst and src.lower() != dst.lower():\n",
    "                edges.append({\"src\": src.lower(), \"dst\": dst.lower(), \"type\": \"mention\", \"tweet_id\": tid, \"date\": dt})\n",
    "\n",
    "        # reply edge\n",
    "        dst = r.get(\"reply_to_user\")\n",
    "        if src and dst and src.lower() != str(dst).lower():\n",
    "            edges.append({\"src\": src.lower(), \"dst\": str(dst).lower(), \"type\": \"reply\", \"tweet_id\": tid, \"date\": dt})\n",
    "\n",
    "        # retweet edge\n",
    "        if r.get(\"is_retweet_flag\"):\n",
    "            dst = r.get(\"retweet_user\")\n",
    "            if src and dst and src.lower() != str(dst).lower():\n",
    "                edges.append({\"src\": src.lower(), \"dst\": str(dst).lower(), \"type\": \"retweet\", \"tweet_id\": tid, \"date\": dt})\n",
    "\n",
    "    E = pd.DataFrame(edges)\n",
    "    # Limpieza básica de aristas\n",
    "    if not E.empty:\n",
    "        E = E.dropna(subset=[\"src\",\"dst\"])\n",
    "        E = E[E[\"src\"] != E[\"dst\"]].reset_index(drop=True)\n",
    "\n",
    "    return df, E\n",
    "\n",
    "# === Ejecutar 3.2 sobre tu df ===\n",
    "df_trafico_rel, edges_trafico = extract_relations(df_trafico)\n",
    "\n",
    "print(\"Tweets con relaciones:\", df_trafico_rel.shape)\n",
    "print(\"Aristas construidas:\", edges_trafico.shape)\n",
    "print(edges_trafico.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "934cf9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "mention    10928\n",
      "reply       4081\n",
      "Name: count, dtype: int64\n",
      "src vacíos: 0 dst vacíos: 0\n",
      "self-loops: 0\n",
      "2023-08-14 04:35:46+00:00 → 2024-09-12 01:21:04+00:00\n",
      "Usuarios únicos (src ∪ dst): 2720\n"
     ]
    }
   ],
   "source": [
    "# 1) Distribución por tipo de relación\n",
    "print(edges_trafico[\"type\"].value_counts())\n",
    "\n",
    "# 2) ¿Hay nodos vacíos o self-loops?\n",
    "print(\"src vacíos:\", edges_trafico[\"src\"].isna().sum(),\n",
    "      \"dst vacíos:\", edges_trafico[\"dst\"].isna().sum())\n",
    "print(\"self-loops:\", (edges_trafico[\"src\"] == edges_trafico[\"dst\"]).sum())\n",
    "\n",
    "# 3) ¿Fechas razonables y usuarios únicos?\n",
    "print(edges_trafico[\"date\"].min(), \"→\", edges_trafico[\"date\"].max())\n",
    "print(\"Usuarios únicos (src ∪ dst):\",\n",
    "      pd.Index(edges_trafico[\"src\"]).union(pd.Index(edges_trafico[\"dst\"])).nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3fd712",
   "metadata": {},
   "source": [
    "#### 3.3) Procesar datos duplicados y normalización de los nombres de usuarios y menciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3763a023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets tras normalización: (5596, 26)\n",
      "Aristas tras normalización: (14931, 5)\n",
      "               src              dst     type             tweet_id  \\\n",
      "0     monymmorales     cc_guatemala  mention  1834029142565658846   \n",
      "1  animaldgalaccia   pncdeguatemala  mention  1834039491826180424   \n",
      "2  animaldgalaccia      mingobguate  mention  1834039491826180424   \n",
      "3  animaldgalaccia   fjimenezmingob  mention  1834039491826180424   \n",
      "4  animaldgalaccia     diegoedeleon  mention  1834039491826180424   \n",
      "5  animaldgalaccia   amilcarmontejo  mention  1834039491826180424   \n",
      "6  animaldgalaccia        traficogt  mention  1834039491826180424   \n",
      "7  animaldgalaccia   pncdeguatemala    reply  1834039491826180424   \n",
      "8   estaciondoblea   amilcarmontejo  mention  1833963729136091179   \n",
      "9   estaciondoblea  aztecanoticiagt  mention  1833963729136091179   \n",
      "\n",
      "                       date  \n",
      "0 2024-09-12 00:39:56+00:00  \n",
      "1 2024-09-12 01:21:04+00:00  \n",
      "2 2024-09-12 01:21:04+00:00  \n",
      "3 2024-09-12 01:21:04+00:00  \n",
      "4 2024-09-12 01:21:04+00:00  \n",
      "5 2024-09-12 01:21:04+00:00  \n",
      "6 2024-09-12 01:21:04+00:00  \n",
      "7 2024-09-12 01:21:04+00:00  \n",
      "8 2024-09-11 20:20:01+00:00  \n",
      "9 2024-09-11 20:20:01+00:00  \n"
     ]
    }
   ],
   "source": [
    "# --- Tweets ---\n",
    "def normalize_user(u):\n",
    "    if not isinstance(u, str):\n",
    "        return None\n",
    "    return u.strip().lower()\n",
    "\n",
    "df_trafico_norm = df_trafico_rel.copy()\n",
    "\n",
    "# Normalizar username, reply_to_user, retweet_user\n",
    "df_trafico_norm[\"username\"] = df_trafico_norm[\"username\"].apply(normalize_user)\n",
    "if \"reply_to_user\" in df_trafico_norm.columns:\n",
    "    df_trafico_norm[\"reply_to_user\"] = df_trafico_norm[\"reply_to_user\"].apply(normalize_user)\n",
    "if \"retweet_user\" in df_trafico_norm.columns:\n",
    "    df_trafico_norm[\"retweet_user\"] = df_trafico_norm[\"retweet_user\"].apply(normalize_user)\n",
    "\n",
    "# Normalizar lista de menciones\n",
    "df_trafico_norm[\"mentions_extracted\"] = df_trafico_norm[\"mentions_extracted\"].apply(\n",
    "    lambda lst: [normalize_user(u) for u in lst if normalize_user(u)] if isinstance(lst, list) else []\n",
    ")\n",
    "\n",
    "# Eliminar tweets duplicados por ID\n",
    "df_trafico_norm = df_trafico_norm.drop_duplicates(subset=[\"tweet_id\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"Tweets tras normalización:\", df_trafico_norm.shape)\n",
    "\n",
    "# --- Aristas ---\n",
    "edges_trafico_norm = edges_trafico.copy()\n",
    "edges_trafico_norm[\"src\"] = edges_trafico_norm[\"src\"].apply(normalize_user)\n",
    "edges_trafico_norm[\"dst\"] = edges_trafico_norm[\"dst\"].apply(normalize_user)\n",
    "\n",
    "# Eliminar duplicados de aristas\n",
    "edges_trafico_norm = edges_trafico_norm.drop_duplicates(subset=[\"src\",\"dst\",\"type\",\"tweet_id\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"Aristas tras normalización:\", edges_trafico_norm.shape)\n",
    "\n",
    "# Vista previa\n",
    "print(edges_trafico_norm.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a8fc2e",
   "metadata": {},
   "source": [
    "#### 3.4) Estructura para el análisis de redes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1016974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodos: 2720\n",
      "Aristas dirigidas (colapsadas): 7338\n",
      "Ejemplo de edges:\n",
      "             src             dst  w_count  w_sum\n",
      "0         01lu88  barevalodeleon        4    5.0\n",
      "1         01lu88  emisorasunidas        3    3.0\n",
      "2         01lu88          mcfrsa        2    3.0\n",
      "3         01lu88       traficogt        3    3.0\n",
      "4         0s_dev       traficogt        2    3.0\n",
      "5   1056_antonio   manfredoguate        2    3.0\n",
      "6   1056_antonio       traficogt        1    1.0\n",
      "7         1601jr       traficogt        2    3.0\n",
      "8  17147128204ca  barevalodeleon        2    3.0\n",
      "9  17147128204ca           pdhgt        1    1.0\n"
     ]
    }
   ],
   "source": [
    "# 1) Asegurar tipos y quedarnos solo con interacciones válidas\n",
    "valid_types = {\"mention\", \"reply\", \"retweet\"}\n",
    "E = edges_trafico_norm.copy()\n",
    "E = E[E[\"type\"].isin(valid_types)].dropna(subset=[\"src\",\"dst\"]).reset_index(drop=True)\n",
    "E[\"src\"] = E[\"src\"].astype(str).str.strip().str.lower()\n",
    "E[\"dst\"] = E[\"dst\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "# 2) Ponderación (opcional). Puedes ajustar estos pesos si lo pide tu rúbrica\n",
    "type_weights = {\"mention\": 1.0, \"reply\": 2.0, \"retweet\": 3.0}\n",
    "E[\"w_type\"] = E[\"type\"].map(type_weights).fillna(1.0)\n",
    "\n",
    "# 3) Agregar múltiples interacciones entre el mismo par (src→dst)\n",
    "#    - w_count: número de interacciones\n",
    "#    - w_sum:   suma de pesos por tipo\n",
    "Agg = (\n",
    "    E.groupby([\"src\",\"dst\"], as_index=False)\n",
    "      .agg(w_count=(\"type\",\"size\"), w_sum=(\"w_type\",\"sum\"))\n",
    ")\n",
    "\n",
    "# 4) Índices de nodos (user → idx) y vectores i,j para matriz dispersa\n",
    "nodes = pd.Index(pd.unique(pd.concat([Agg[\"src\"], Agg[\"dst\"]], ignore_index=True)))\n",
    "node_to_idx = {u: i for i, u in enumerate(nodes)}\n",
    "\n",
    "row = Agg[\"src\"].map(node_to_idx).to_numpy()\n",
    "col = Agg[\"dst\"].map(node_to_idx).to_numpy()\n",
    "\n",
    "# 5) Construir matrices dispersas (COO→CSR):\n",
    "#    - adj_count: peso = #interacciones\n",
    "#    - adj_weight: peso = suma de pesos por tipo\n",
    "adj_count  = coo_matrix((Agg[\"w_count\"].to_numpy(), (row, col)), shape=(len(nodes), len(nodes))).tocsr()\n",
    "adj_weight = coo_matrix((Agg[\"w_sum\"].to_numpy(),   (row, col)), shape=(len(nodes), len(nodes))).tocsr()\n",
    "\n",
    "# 6) Resultado principal para análisis de redes\n",
    "#    - Edge list final: Agg (src, dst, w_count, w_sum)\n",
    "#    - Matriz de adyacencia (CSR): adj_count / adj_weight\n",
    "#    - Mapeo de nodos: nodes (índice→usuario) y node_to_idx (usuario→índice)\n",
    "\n",
    "print(f\"Nodos: {len(nodes)}\")\n",
    "print(f\"Aristas dirigidas (colapsadas): {Agg.shape[0]}\")\n",
    "print(\"Ejemplo de edges:\")\n",
    "print(Agg.head(10))\n",
    "\n",
    "# (Opcional) funciones auxiliares prácticas\n",
    "def neighbors_out(user, topk=10, use_weights=\"count\"):\n",
    "    \"\"\"Vecinos salientes y pesos desde 'user'.\"\"\"\n",
    "    if user not in node_to_idx:\n",
    "        return pd.DataFrame(columns=[\"dst\",\"weight\"])\n",
    "    i = node_to_idx[user]\n",
    "    mat = adj_count if use_weights==\"count\" else adj_weight\n",
    "    idxs = mat[i].indices\n",
    "    vals = mat[i].data\n",
    "    dst_users = nodes[idxs]\n",
    "    out = pd.DataFrame({\"dst\": dst_users, \"weight\": vals}).sort_values(\"weight\", ascending=False)\n",
    "    return out.head(topk).reset_index(drop=True)\n",
    "\n",
    "def neighbors_in(user, topk=10, use_weights=\"count\"):\n",
    "    \"\"\"Vecinos entrantes y pesos hacia 'user'.\"\"\"\n",
    "    if user not in node_to_idx:\n",
    "        return pd.DataFrame(columns=[\"src\",\"weight\"])\n",
    "    j = node_to_idx[user]\n",
    "    mat = adj_count if use_weights==\"count\" else adj_weight\n",
    "    # columna j (entrantes) -> usamos la transpuesta\n",
    "    col_vec = mat[:, j].tocoo()\n",
    "    src_users = nodes[col_vec.row]\n",
    "    out = pd.DataFrame({\"src\": src_users, \"weight\": col_vec.data}).sort_values(\"weight\", ascending=False)\n",
    "    return out.head(topk).reset_index(drop=True)\n",
    "\n",
    "# Ejemplos de uso:\n",
    "# neighbors_out(\"traficogt\", topk=5, use_weights=\"count\")\n",
    "# neighbors_in (\"traficogt\", topk=5, use_weights=\"weight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23481e1",
   "metadata": {},
   "source": [
    "Se construyó la estructura de grafo dirigido que resume las interacciones entre usuarios de la cuenta @traficogt. El resultado final muestra una red con 2,720 nodos únicos (usuarios que participan) y 7,338 aristas dirigidas colapsadas, lo que significa que se agruparon todas las menciones, respuestas y retuits entre cada par de usuarios para evitar repeticiones. Cada arista registra no solo cuántas veces ocurrió la interacción (w_count), sino también un peso acumulado (w_sum) que diferencia la intensidad según el tipo de relación (mención=1, respuesta=2, retuit=3). De esta forma, la red queda representada en un formato eficiente que permite identificar con claridad quién interactúa con quién y con qué fuerza, preparando la base para calcular métricas de centralidad y detectar comunidades en el análisis posterior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
